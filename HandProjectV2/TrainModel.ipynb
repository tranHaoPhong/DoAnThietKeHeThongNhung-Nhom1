{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 39ms/step - loss: 24.1632 - accuracy: 0.1667 - val_loss: 6.1496 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 3.0369 - accuracy: 0.3625 - val_loss: 1.9166 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3198 - accuracy: 0.4167 - val_loss: 0.8280 - val_accuracy: 0.6167\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7957 - accuracy: 0.6708 - val_loss: 0.5500 - val_accuracy: 0.7667\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.6690 - accuracy: 0.7333 - val_loss: 0.4380 - val_accuracy: 0.8167\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.4830 - accuracy: 0.8292 - val_loss: 0.2661 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3981 - accuracy: 0.8583 - val_loss: 0.2967 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3648 - accuracy: 0.8583 - val_loss: 0.2342 - val_accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.2771 - accuracy: 0.9250 - val_loss: 0.2199 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2968 - accuracy: 0.8833 - val_loss: 0.1312 - val_accuracy: 0.9667\n",
      "2/2 - 0s - loss: 0.1312 - accuracy: 0.9667 - 28ms/epoch - 14ms/step\n",
      "Test accuracy: 0.9666666388511658\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "[1.2947931e-02 9.6859163e-01 1.8454919e-02 3.8203279e-06 3.8510219e-08\n",
      " 1.1139550e-09 4.3974461e-14 9.2440541e-13 1.7294818e-13 4.8617260e-12\n",
      " 1.2937777e-07 2.0657789e-15 7.8185368e-11 2.1749742e-12 1.5632013e-06\n",
      " 8.9954122e-10 1.0505244e-11 5.8436009e-13 7.9275277e-14 2.3015543e-09\n",
      " 3.9679127e-15 1.2347159e-13 7.9677983e-12 2.6706705e-12 9.8815243e-14]\n",
      "1\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\tranh\\AppData\\Local\\Temp\\tmpy4h2tk3j\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tranh\\AppData\\Local\\Temp\\tmpy4h2tk3j\\assets\n",
      "c:\\Users\\tranh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = 'image_data.csv'\n",
    "model_save_path = 'HandModel.keras'\n",
    "tflite_save_path = 'HandModel.tflite'\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv(dataset)\n",
    "\n",
    "# Phân tách nhãn và dữ liệu ảnh\n",
    "labels = data.iloc[:, 0].values\n",
    "images = data.iloc[:, 1:].values\n",
    "\n",
    "# Chỉnh sửa nhãn để bắt đầu từ 0 thay vì 1\n",
    "#labels = labels - 1\n",
    "\n",
    "# Định hình lại dữ liệu ảnh\n",
    "images = images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Chuẩn hóa dữ liệu ảnh\n",
    "#images = images / 255.0\n",
    "\n",
    "# Chuyển đổi nhãn thành dạng one-hot\n",
    "labels = to_categorical(labels, num_classes=25)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tăng cường dữ liệu\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Xây dựng mô hình CNN\n",
    "model = Sequential()\n",
    "# Giảm số lượng bộ lọc từ 65 xuống 32\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "# Giảm số lượng bộ lọc từ 40 xuống 32\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "# Loại bỏ Dropout hoặc giảm tỷ lệ Dropout\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "# Giảm số lượng bộ lọc từ 25 xuống 16\n",
    "model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "# Giảm số lượng units từ 256 xuống 128\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "# Loại bỏ Dropout hoặc giảm tỷ lệ Dropout\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 25 , activation = 'softmax'))\n",
    "\n",
    "\n",
    "# Compile mô hình\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình với dữ liệu tăng cường\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path)\n",
    "\n",
    "# Loading the saved model\n",
    "#model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "\n",
    "# Tạo một hàm để tạo tập dữ liệu đại diện từ tập huấn luyện\n",
    "def representative_dataset():\n",
    "    for data in X_train:\n",
    "        # Reshape dữ liệu về dạng (1, height, width, channel) và chuyển đổi sang kiểu numpy float32\n",
    "        yield [data.reshape(1, 28, 28, 1).astype(np.float32)]\n",
    "\n",
    "# Chuyển đổi mô hình với quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset  # Thêm representative dataset\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "with open(tflite_save_path, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += 'const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str\n",
    "\n",
    "c_model_name = 'HandModel'       # Will be given .h suffix\n",
    "\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_quantized_model, c_model_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
