{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "180/180 [==============================] - 4s 17ms/step - loss: 3.9028 - accuracy: 0.1687 - val_loss: 2.0197 - val_accuracy: 0.3666\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 1.7290 - accuracy: 0.4614 - val_loss: 1.0598 - val_accuracy: 0.6439\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 1.0757 - accuracy: 0.6460 - val_loss: 0.6195 - val_accuracy: 0.7895\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.8594 - accuracy: 0.7112 - val_loss: 0.4436 - val_accuracy: 0.8495\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.6307 - accuracy: 0.7837 - val_loss: 0.3383 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.5211 - accuracy: 0.8234 - val_loss: 0.1650 - val_accuracy: 0.9449\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.4507 - accuracy: 0.8471 - val_loss: 0.1739 - val_accuracy: 0.9477\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.3535 - accuracy: 0.8799 - val_loss: 0.1722 - val_accuracy: 0.9359\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.3173 - accuracy: 0.8933 - val_loss: 0.1516 - val_accuracy: 0.9415\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2648 - accuracy: 0.9102 - val_loss: 0.0623 - val_accuracy: 0.9791\n",
      "45/45 - 0s - loss: 0.0623 - accuracy: 0.9791 - 313ms/epoch - 7ms/step\n",
      "Test accuracy: 0.9790940880775452\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[9.8540199e-01 2.8678919e-08 1.8635188e-16 1.5440932e-15 1.4352521e-02\n",
      " 1.9684367e-09 9.3839282e-15 2.6339342e-16 8.2416989e-07 7.4974243e-25\n",
      " 1.3268354e-19 2.2592629e-19 2.4285693e-04 1.2370992e-06 9.6101647e-11\n",
      " 5.3262657e-13 1.7007762e-10 4.4909367e-20 5.4156055e-07 1.4097574e-16\n",
      " 2.4003509e-21 8.8550698e-19 4.3055125e-15 7.3634505e-15 1.9944044e-12]\n",
      "0\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\tranh\\AppData\\Local\\Temp\\tmpi_fo195k\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tranh\\AppData\\Local\\Temp\\tmpi_fo195k\\assets\n",
      "c:\\Users\\tranh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = 'image_data.csv'\n",
    "model_save_path = 'HandModel.keras'\n",
    "tflite_save_path = 'HandModel.tflite'\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv(dataset)\n",
    "\n",
    "# Phân tách nhãn và dữ liệu ảnh\n",
    "labels = data.iloc[:, 0].values\n",
    "images = data.iloc[:, 1:].values\n",
    "\n",
    "# Chỉnh sửa nhãn để bắt đầu từ 0 thay vì 1\n",
    "#labels = labels - 1\n",
    "\n",
    "# Định hình lại dữ liệu ảnh\n",
    "images = images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Chuẩn hóa dữ liệu ảnh\n",
    "#images = images / 255.0\n",
    "\n",
    "# Chuyển đổi nhãn thành dạng one-hot\n",
    "labels = to_categorical(labels, num_classes=25)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tăng cường dữ liệu\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Xây dựng mô hình CNN\n",
    "model = Sequential()\n",
    "# Giảm số lượng bộ lọc từ 65 xuống 32\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "# Giảm số lượng bộ lọc từ 40 xuống 32\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "# Loại bỏ Dropout hoặc giảm tỷ lệ Dropout\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "# Giảm số lượng bộ lọc từ 25 xuống 16\n",
    "model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "# Giảm số lượng units từ 256 xuống 128\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "# Loại bỏ Dropout hoặc giảm tỷ lệ Dropout\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 25 , activation = 'softmax'))\n",
    "\n",
    "\n",
    "# Compile mô hình\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình với dữ liệu tăng cường\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path)\n",
    "\n",
    "# Loading the saved model\n",
    "#model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "\n",
    "# Tạo một hàm để tạo tập dữ liệu đại diện từ tập huấn luyện\n",
    "def representative_dataset():\n",
    "    for data in X_train:\n",
    "        # Reshape dữ liệu về dạng (1, height, width, channel) và chuyển đổi sang kiểu numpy float32\n",
    "        yield [data.reshape(1, 28, 28, 1).astype(np.float32)]\n",
    "\n",
    "# Chuyển đổi mô hình với quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset  # Thêm representative dataset\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "with open(tflite_save_path, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += 'const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str\n",
    "\n",
    "c_model_name = 'HandModel'       # Will be given .h suffix\n",
    "\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_quantized_model, c_model_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
